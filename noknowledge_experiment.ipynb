{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from utils import copy_dataset, add_self_relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_str     : str   = \"Amazon_Books-part\"\n",
    "test_type       : str   = \"fact\"\n",
    "device          : torch.device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert interaction file to kg file\n",
    "suffix = str(device).split(':')[-1]\n",
    "fake_dataset = '{}-fake-temp{}'.format(dataset_str, suffix)\n",
    "src_path = './dataset/{}/'.format(dataset_str)\n",
    "temp_path = os.path.join('./dataset/', fake_dataset)\n",
    "copy_dataset(suffix, src_path, temp_path, dataset_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_pd = pd.read_table(os.path.join(temp_path, fake_dataset+'.inter'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg_pd = inter_pd.loc[:, ['user_id:token', 'item_id:token']]\n",
    "kg_pd.insert(1, 'relation_id:token', ['interaction']*kg_pd.shape[0])\n",
    "kg_pd.columns = ['head_id:token', 'relation_id:token', 'tail_id:token']\n",
    "\n",
    "kg_pd_t = inter_pd.loc[:, ['item_id:token', 'user_id:token']]\n",
    "kg_pd_t.insert(1, 'relation_id:token', ['interaction_t']*kg_pd_t.shape[0])\n",
    "kg_pd_t.columns = ['head_id:token', 'relation_id:token', 'tail_id:token']\n",
    "\n",
    "kg_pd = pd.concat([kg_pd, kg_pd_t], ignore_index=True)\n",
    "\n",
    "item_list = list(set(inter_pd.loc[:,'item_id:token']))\n",
    "link_pd = pd.DataFrame({'item_id:token':item_list, 'entity_id:token':item_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg_pd.to_csv(os.path.join(temp_path, fake_dataset + '.kg'), '\\t', index=False)\n",
    "link_pd.to_csv(os.path.join(temp_path, fake_dataset + '.link'), '\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import random\n",
    "import recbole\n",
    "from shutil import rmtree\n",
    "\n",
    "from recbole.config.configurator import Config\n",
    "from recbole.model.knowledge_aware_recommender import *\n",
    "from MCRec import MCRec\n",
    "\n",
    "from logging import getLogger\n",
    "from recbole.utils import init_logger, init_seed\n",
    "from utils import get_model\n",
    "from recbole.trainer import KGTrainer\n",
    "from recbole.config import Config\n",
    "from recbole.sampler import Sampler\n",
    "from recbole.data.dataloader import FullSortEvalDataLoader\n",
    "from recbole.data import create_dataset, data_preparation\n",
    "from recbole.data.dataset import Dataset, KnowledgeBasedDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment settings\n",
    "dataset_str     : str   = fake_dataset\n",
    "test_type       : str   = \"fact\"\n",
    "device          : torch.device = torch.device('cuda:0')\n",
    "rate            : float         = 0.25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07 Oct 18:17    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 7972\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = dataset/Amazon_Books-part-fake-temp0\n",
      "checkpoint_dir = saved0/\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 300\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [0.8, 0.1, 0.1]}, 'group_by': 'user', 'order': 'RO', 'mode': 'full'}\n",
      "repeatable = False\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [10]\n",
      "valid_metric = MRR@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id', 'rating', 'timestamp'], 'kg': ['head_id', 'relation_id', 'tail_id'], 'link': ['item_id', 'entity_id']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = True\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 64\n",
      "loss_function = inner_product\n",
      "margin = 1.0\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.KNOWLEDGE\n",
      "MODEL_INPUT_TYPE = InputType.PAIRWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cuda\n",
      "eval_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n",
      "07 Oct 18:17    INFO  [Training]: train_batch_size = [2048] train_neg_sample_args: [{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\n",
      "07 Oct 18:17    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [0.8, 0.1, 0.1]}, 'group_by': 'user', 'order': 'RO', 'mode': 'full'}]\n"
     ]
    }
   ],
   "source": [
    "config_dict = {'seed':random.randint(0, 10000), 'gpu_id':0, 'checkpoint_dir':'saved{}/'.format(str(device).split(':')[-1])}\n",
    "\n",
    "# evaluation for fake kg\n",
    "config = Config(model=CFKG, dataset=dataset_str, config_dict=config_dict)\n",
    "init_logger(config)\n",
    "logger = getLogger()\n",
    "logger.info(config)\n",
    "config['device'] = device\n",
    "\n",
    "# dataset filtering\n",
    "dataset = create_dataset(config)\n",
    "\n",
    "# dataset splitting\n",
    "train_data, valid_data, test_data = data_preparation(config, dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1,  ..., 2, 2, 2])\n",
      "The batch_size of interaction: 226166\n",
      "    head_id, torch.Size([226166]), cpu, torch.int64\n",
      "    relation_id, torch.Size([226166]), cpu, torch.int64\n",
      "    tail_id, torch.Size([226166]), cpu, torch.int64\n",
      "\n",
      "\n",
      "The batch_size of interaction: 226166\n",
      "    head_id, torch.Size([226166]), cpu, torch.int64\n",
      "    relation_id, torch.Size([226166]), cpu, torch.int64\n",
      "    tail_id, torch.Size([226166]), cpu, torch.int64\n",
      "\n",
      "\n",
      "The batch_size of interaction: 226166\n",
      "    head_id, torch.Size([226166]), cpu, torch.int64\n",
      "    relation_id, torch.Size([226166]), cpu, torch.int64\n",
      "    tail_id, torch.Size([226166]), cpu, torch.int64\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dataset.kg_feat.relation_id)\n",
    "print(train_data._dataset.kg_feat)\n",
    "print(test_data._dataset.kg_feat)\n",
    "print(valid_data._dataset.kg_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size of interaction: 183892\n",
      "    head_id, torch.Size([183892]), cpu, torch.int64\n",
      "    relation_id, torch.Size([183892]), cpu, torch.int64\n",
      "    tail_id, torch.Size([183892]), cpu, torch.int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "head = dataset.token2id(dataset.entity_field, dataset.id2token(dataset.uid_field, train_data._dataset.inter_feat.user_id))\n",
    "tail = dataset.token2id(dataset.entity_field, dataset.id2token(dataset.iid_field, train_data._dataset.inter_feat.item_id))\n",
    "relation = [1]*len(head)+[2]*len(head)\n",
    "interaction = {'head_id':np.concatenate([head,tail]), 'relation_id':relation, 'tail_id':np.concatenate([tail,head])}\n",
    "print(recbole.data.interaction.Interaction(interaction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.kg_feat = interaction\n",
    "# train_data._dataset.kg_feat = interaction\n",
    "# test_data._dataset.kg_feat = interaction\n",
    "# valid_data._dataset.kg_feat = interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05 Oct 21:32    INFO  epoch 0 training [time: 0.36s, train loss: 61.2988]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[39m=\u001b[39m CFKG(config, dataset)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      2\u001b[0m trainer \u001b[39m=\u001b[39m KGTrainer(config, model)\n\u001b[0;32m----> 3\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(train_data, valid_data, show_progress\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/.conda/envs/zhn_recbole/lib/python3.9/site-packages/recbole/trainer/trainer.py:465\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, train_data, valid_data, verbose, saved, show_progress, callback_fn)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[39mif\u001b[39;00m (epoch_idx \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval_step \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    464\u001b[0m     valid_start_time \u001b[39m=\u001b[39m time()\n\u001b[0;32m--> 465\u001b[0m     valid_score, valid_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_valid_epoch(\n\u001b[1;32m    466\u001b[0m         valid_data, show_progress\u001b[39m=\u001b[39;49mshow_progress\n\u001b[1;32m    467\u001b[0m     )\n\u001b[1;32m    468\u001b[0m     (\n\u001b[1;32m    469\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_valid_score,\n\u001b[1;32m    470\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcur_step,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    478\u001b[0m         bigger\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalid_metric_bigger,\n\u001b[1;32m    479\u001b[0m     )\n\u001b[1;32m    480\u001b[0m     valid_end_time \u001b[39m=\u001b[39m time()\n",
      "File \u001b[0;32m~/.conda/envs/zhn_recbole/lib/python3.9/site-packages/recbole/trainer/trainer.py:284\u001b[0m, in \u001b[0;36mTrainer._valid_epoch\u001b[0;34m(self, valid_data, show_progress)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_valid_epoch\u001b[39m(\u001b[39mself\u001b[39m, valid_data, show_progress\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    274\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Valid the model with valid data\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \n\u001b[1;32m    276\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[39m        dict: valid result\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 284\u001b[0m     valid_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(\n\u001b[1;32m    285\u001b[0m         valid_data, load_best_model\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, show_progress\u001b[39m=\u001b[39;49mshow_progress\n\u001b[1;32m    286\u001b[0m     )\n\u001b[1;32m    287\u001b[0m     valid_score \u001b[39m=\u001b[39m calculate_valid_score(valid_result, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalid_metric)\n\u001b[1;32m    288\u001b[0m     \u001b[39mreturn\u001b[39;00m valid_score, valid_result\n",
      "File \u001b[0;32m~/.conda/envs/zhn_recbole/lib/python3.9/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/zhn_recbole/lib/python3.9/site-packages/recbole/trainer/trainer.py:614\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_data, load_best_model, model_file, show_progress)\u001b[0m\n\u001b[1;32m    602\u001b[0m iter_data \u001b[39m=\u001b[39m (\n\u001b[1;32m    603\u001b[0m     tqdm(\n\u001b[1;32m    604\u001b[0m         eval_data,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[39melse\u001b[39;00m eval_data\n\u001b[1;32m    611\u001b[0m )\n\u001b[1;32m    613\u001b[0m num_sample \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m--> 614\u001b[0m \u001b[39mfor\u001b[39;00m batch_idx, batched_data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(iter_data):\n\u001b[1;32m    615\u001b[0m     num_sample \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(batched_data)\n\u001b[1;32m    616\u001b[0m     interaction, scores, positive_u, positive_i \u001b[39m=\u001b[39m eval_func(batched_data)\n",
      "File \u001b[0;32m~/.conda/envs/zhn_recbole/lib/python3.9/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.conda/envs/zhn_recbole/lib/python3.9/site-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.conda/envs/zhn_recbole/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[0;32m~/.conda/envs/zhn_recbole/lib/python3.9/site-packages/recbole/data/dataloader/general_dataloader.py:254\u001b[0m, in \u001b[0;36mFullSortEvalDataLoader.collate_fn\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_sequential:\n\u001b[1;32m    253\u001b[0m     user_df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muser_df[index]\n\u001b[0;32m--> 254\u001b[0m     uid_list \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(user_df[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49muid_field])\n\u001b[1;32m    256\u001b[0m     history_item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muid2history_item[uid_list]\n\u001b[1;32m    257\u001b[0m     positive_item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muid2positive_item[uid_list]\n",
      "File \u001b[0;32m~/.conda/envs/zhn_recbole/lib/python3.9/site-packages/torch/_tensor.py:940\u001b[0m, in \u001b[0;36mTensor.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_get_tracing_state():\n\u001b[1;32m    932\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    933\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIterating over a tensor might cause the trace to be incorrect. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    934\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPassing a tensor of different shape won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt change the number of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    938\u001b[0m         stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m    939\u001b[0m     )\n\u001b[0;32m--> 940\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39miter\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49munbind(\u001b[39m0\u001b[39;49m))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = CFKG(config, dataset).to(device)\n",
    "trainer = KGTrainer(config, model)\n",
    "trainer.fit(train_data, valid_data, show_progress=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zhn_recbole",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
